quit()
a <- "Hello!"
a
print(a)
clear
rm(ls())
ls()
rm(a)
ls()
quit()
pwd
set.pwd
some <- c(1,2,3,4)
names(some) <- c('changu','mangu','nangu','pangu')
some['changu']
some[0]
some[1]
a <- list(1,2,2)
a
a[1]
a[2]
a[0]
rm(list=ls())
a = 4
a <- 4
if(a >= 4){}
if(a >= 5){print ("Yup")}
if(a >= 5){print ("Yup")}
if(a >= 5){print ("Yup")}
1 < 2
1 > 2
rm(list =ls())
quit()
install.packages(c("tidyverse","ggplot","dplyr"))
install.packages("ggplot2")
setwd("\users\sukanto\WD")
sales <- read.csv('\users\sukanto\WD\Walmart_Store_sales.csv')
sales <- read.csv('Walmart_Store_sales.csv')
sales <- read.csv('/users/sukanto/WD/Walmart_Store_sales.csv')
sales
View(sales)
str(sale)
str(sales)
max(sales$Weekly_Sales)
min(sales$Weekly_Sales)
mean(sales$Weekly_Sales)
counts <- sales(sales$Weekly_Sales)
counts <- table(sales$Weekly_Sales)
barplot(counts)
counts <- table(sales$Holiday_Flag)
barplot(counts)
reg_counts <- table(sales$Store)
barplot(reg_counts)
pie(reg_counts)
hist(reg_counts)
hist(counts)
hist(sales$Weekly_Sales)
hist(sales$Weekly_Sales,breaks = 10)
plot(density(sales$Weekly_Sales))
rm(list = ls())
q()
pnorm(84, mean = 72, sd = 15.2, lower.tail = FALSE)
qt(c(0.025,0.975), df = 5)
r = c(t(as.matrix(4.4,5.6,7.7,9.1)))
n <- 6
k <- 3
n <- 6
f <- c(4.4,5.6,7.7,9.1)
tm = gl(k,1,n*k,factor(f))
av = aov(r~tm)
library(MASS)
head(survey)
tbl = table(survey$Smoke, survey$Exer)
tbl
chisq.test(tbl)
rm(list = ls())
q()
ggplot(sales, aes(x = sales$Weekly_Sales, y = sales$Temperature) + geom_line()
dev.off()
rm(list=ls)
rm(list=ls())
dev.off()
quit()
help("bar")
apropos("bar")
?bar
x = 8
print x
print(x)
x<-y<-6
print(x)
b=7
a<-6<-b
q()
txt <- "World!"
print("Hello", txt)
print("Hello" + txt)
"Hello" + txt
x <- 10.5
typeof(x)
class(x)
str <- "Hello"
length(str)
rm(list=ls())
q()
q()
getwd()
setwd('/users/sukanto/WD/Walmart_StoreSale_Analysis/Walmart_StoreSales_Analysis')
my_packages <- c("ggplot2","lubridate","dplyr", "ggplot2","lubridate","raster","zoo","sp","usdm","lmtest")
my_packages <- c("ggplot2","lubridate","dplyr", "plyr","ggplot2",
"lubridate","raster","zoo","sp",
"usdm","lmtest","forecast")
lapply(my_packages, require, character.only = TRUE)
my_packages <- c("ggplot2","lubridate","dplyr", "plyr","ggplot2",
"lubridate","raster","zoo","sp",
"usdm","lmtest","fpp2")
lapply(my_packages, require, character.only = TRUE)
install.packages("fpp2")
#Installing and loading packages
my_packages <- c("ggplot2","lubridate","dplyr", "plyr","ggplot2",
"lubridate","raster","zoo","sp",
"usdm","lmtest","forecast")
lapply(my_packages, require, character.only = TRUE)
stores <- read.csv('Walmart_Store_sales.csv')
head(stores)
summary(stores)
colnames(stores)
str(stores)
sum(is.na(stores))
duplicated(stores)
stores$Date <- as.Date(stores$Date, format = "%m-%d-%Y")
str(stores)
each_store <- aggregate(Weekly_Sales ~ Store, stores,sum)
each_store <- arrange(each_store, desc(Weekly_Sales))
max(each_store)
options(scipen = 999)
jpeg('max_store_sale.jpg')
ggplot(each_store, aes(Store, Weekly_Sales)) +
geom_bar(stat = 'identity', color = ' dark blue',
fill = ' dark blue')
dev.off()
each_store_sd <- aggregate(Weekly_Sales~Store,stores, sd)
each_store_sd <- rename(each_store_sd, c(Weekly_Sales = 'SD_Sales'))
each_store_mean <- aggregate(Weekly_Sales~Store, stores, mean)
each_store_mean <- rename(each_store_mean, c(Weekly_Sales = 'Mean_Sales'))
each_store_mean_sd <- cbind(each_store_mean, each_store_sd)
each_store_mean_sd_coeff <- transform(each_store_mean_sd, Coeff = SD_Sales/Mean_Sales)
View(stores)
stores$Date <- as.Date(stores$Date, format = "%m-%d-%Y")
str(stores)
#Sales Forecast
#Approach 1: Linear Model
fit <- lm(Weekly_Sales ~ Holiday_Flag + Temperature + Fuel_Price
+ CPI + Unemplpoyment, stores)
#Sales Forecast
#Approach 1: Linear Model
fit <- lm(Weekly_Sales ~ Holiday_Flag + Temperature + Fuel_Price
+ CPI + Unemployment, stores)
summary(fit)
#Dropping the insignificant vars ie Temperature and Fuel Price
fit1 <- lm(Weekly_Sales ~ Holiday_Flag + CPI + Unemployment, stores)
summary(fit1)
#Time series model
# visually identifying if data is fit for time series
store1 <- aggregate(Weekly_Sales~Date,stores,sum)
View(store1)
plot(store1, type = 'l')
class(store1)
str(store1)
#preparing data for ARIMA model
store_month_year = transform(stores,Year_Sale =as.numeric(format(Date,"%Y"))
,Month_Sale =as.numeric(format(Date,"%m")))
store_month_year_filtered <- select(store_month_year,Weekly_Sales,Year_Sale,Month_Sale)
#preparing data for ARIMA model
store_month_year <- transform(stores,Year_Sale =as.numeric(format(Date,"%Y"))
,Month_Sale =as.numeric(format(Date,"%m")))
store_month_year_filtered <- select(store_month_year,Weekly_Sales,Year_Sale,Month_Sale)
View(stores)
rm(list = ls())
my_packages <- c("ggplot2","lubridate","dplyr", "plyr","ggplot2",
"lubridate","raster","zoo","sp",
"usdm","lmtest","forecast")
lapply(my_packages, require, character.only = TRUE)
stores <- read.csv('Walmart_Store_sales.csv')
head(stores)
summary(stores)
colnames(stores)
str(stores)
sum(is.na(stores))
duplicated(stores)
stores$Date <- as.Date(stores$Date, format = "%m-%d-%Y")
str(stores)
stores_month_year <- transform(stores,Year =as.numeric(format(Date,"%Y"))
,Month =as.numeric(format(Date,"%m")))
Summarized_View <- aggregate(Weekly_Sales~Month+Year,stores_month_year,sum)
Insight_data <- arrange(Summarized_View,desc(Weekly_Sales))
View(Insight_data)
store_month_year <- transform(stores,Year_Sale =as.numeric(format(Date,"%Y"))
,Month_Sale =as.numeric(format(Date,"%m")))
store_month_year_filtered <- select(store_month_year,Weekly_Sales,Year_Sale,Month_Sale)
View(stores_month_year)
store_month_year <- transform(stores,Year =as.numeric(format(Date,"%Y"))
,Month =as.numeric(format(Date,"%m")))
store_month_year_filtered <- select(store_month_year,Weekly_Sales,Year,Month)
#preparing data for ARIMA model
store_month_year <- transform(stores,Year =as.numeric(format(Date,"%Y"))
,Month =as.numeric(format(Date,"%m")))
store_month_year_filtered <- select(store_month_year,Weekly_Sales,Year,Month)
rm(list=ls())
my_packages <- c("ggplot2","lubridate","dplyr", "plyr","ggplot2",
"lubridate","raster","zoo","sp",
"usdm","lmtest","forecast")
lapply(my_packages, require, character.only = TRUE)
stores <- read.csv('Walmart_Store_sales.csv')
head(stores)
summary(stores)
colnames(stores)
str(stores)
sum(is.na(stores))
duplicated(stores)
stores$Date <- as.Date(stores$Date, format = c("%m-%d-%Y"))
str(stores)
View(stores)
stores$Date <- as.Date(stores$Date, format = c("%m-%d-%Y"))
str(stores)
View(stores)
store_month_year <- transform(stores,Year =as.numeric(format(Date,"%Y"))
,Month =as.numeric(format(Date,"%m")))
store_month_year_filtered <- select(store_month_year,Weekly_Sales,Year,Month)
View(store_month_year)
#preparing data for ARIMA model
library(dplyr)
store_month_year <- transform(stores,Year =as.numeric(format(Date,"%Y"))
,Month =as.numeric(format(Date,"%m")))
store_month_year_filtered <- select(store_month_year,Weekly_Sales,Year,Month)
store_month_year <- transform(stores,Year =as.numeric(format(Date,"%Y"))
,Month =as.numeric(format(Date,"%m")))
store_month_year_filtered %>% dplyr:: select(store_month_year,Weekly_Sales,Year,Month)
%>% dplyr:: select(store_month_year,Weekly_Sales,Year,Month)
stores_month_year %>% dplyr:: select(store_month_year,Weekly_Sales,Year,Month)
stores_month_year %>% dplyr:: select(Weekly_Sales,Year,Month)
store_month_year %>% dplyr:: select(Weekly_Sales,Year,Month)
store_month_year_filtered <- store_month_year %>% dplyr:: select(Weekly_Sales,Year,Month)
View(store_month_year_filtered)
# rolling up sales at month level
Walmart_Rolledup <- aggregate(Weekly_Sales~Year+Month,
store_month_year_filtered,sum)
View(Walmart_Rolledup)
# sorting in year and month order
Walmart_sorted <- arrange(Walmart_Rolledup,Year_Sale,Month_Sale)
# sorting in year and month order
Walmart_sorted <- arrange(Walmart_Rolledup,Year,Month)
View(Walmart_sorted)
# creating a Column with month and year of sale
Walmart_TS <- transform(Walmart_sorted,Time_Of_Sale = as.Date(paste(Year_Sale,"-",Month_Sale,"-",1,sep=""),
format="%Y-%m-%d"))[,c(4,3)]
# creating a Column with month and year of sale
Walmart_TS <- transform(Walmart_sorted,Time_Of_Sale = as.Date(paste(Year,"-",Month,"-",1,sep=""),
format="%Y-%m-%d"))[,c(4,3)]
# creating a Column with month and year of sale
Walmart_TS <- transform(Walmart_sorted,
Time_Of_Sale = as.Date(paste(Year,"-",Month,"-",1,sep=""),
format="%Y-%m-%d"))[,c(4,3)]
View(Walmart_TS)
# Build up ARIMA model to forecast last 6 months i.e as in input utilize only till
# Predict next 6 months i.e June to Oct 2010. Check for MAPE
# Building ARIMA model
Walmart_ARIMA <- auto.arima(Walmart_TS[1:30,2])
View(Walmart_ARIMA)
Walmart_ARIMA = arima(Walmart_TS[1:30,2],order=c(2,1,2))
View(Walmart_ARIMA)
Forecasted_Sale <- forecast(Walmart_ARIMA,h=6)
View(Forecasted_Sale)
Forecasted_Sale
plot(Forecasted_Sale)
jpeg('sales_forecast_6m.jpg')
plot(Forecasted_Sale)
dev.off()
# 6 months forecast
Forecasted_Sales <- as.data.frame(Forecasted_Sale)
Forecasted_Sales_6m <- Forecasted_Sales[,1]
View(Forecasted_Sales_6m)
View(Forecasted_Sales)
View(Forecasted_Sale)
View(Forecasted_Sales)
# 6 m actual
Actual_Sales_6m <- Walmart_TS[31:36,]
View(Actual_Sales_6m)
# concatenating 6 m forecast and actual
Actual_vs_Forecast_last_6_m <- cbind(Forecasted_Sales_6m,Actual_Sales_6m)
View(Actual_vs_Forecast_last_6_m)
Actual_vs_Forecst_last_6_m_deviation <- transform(Actual_vs_Forecst_last_6_m,
Errors = abs(Forecasted_Sales_6m-Weekly_Sales)/Weekly_Sales)
Actual_vs_Forecst_last_6_m_deviation <- transform(Actual_vs_Forecast_last_6_m,
Errors = abs(Forecasted_Sales_6m-Weekly_Sales)/Weekly_Sales)
Actual_vs_Forecast_last_6_m_deviation <- transform(Actual_vs_Forecast_last_6_m,
Errors = abs(Forecasted_Sales_6m-Weekly_Sales)/Weekly_Sales)
View(Actual_vs_Forecast_last_6_m_deviation)
MAPE <- mean(Actual_vs_Forecst_last_6_m_deviation$Errors)
MAPE
each_store_sd <- aggregate(Weekly_Sales~Store,stores, sd)
each_store_sd <- rename(each_store_sd, c(Weekly_Sales = 'SD_Sales'))
View(each_store_sd)
max(each_store_sd)
each_store_mean <- aggregate(Weekly_Sales~Store, stores, mean)
each_store_mean <- rename(each_store_mean, c(Weekly_Sales = 'Mean_Sales'))
each_store_mean_sd <- cbind(each_store_mean, each_store_sd)
each_store_mean_sd_coeff <- transform(each_store_mean_sd, Coeff = SD_Sales/Mean_Sales)
View(each_store_mean_sd_coeff)
quarter_store <- transform(stores, Q_Flag= ifelse((Date>='2012-04-01' & Date<= '2012-06-30'),"Q2_2012",
ifelse((Date>='2012-07-01' & Date<= '2012-09-30'),"Q3_2012","-")))
# confirming start and end date for each quarter
aggregate(Date ~ Q_Flag, quarter_store, min)
aggregate(Date ~ Q_Flag, quarter_store, max)
# summarizing and then reshaping
quarter_store_sum <- aggregate(Weekly_Sales~Store+Q_Flag,quarter_store,sum)
str(quarter_store_sum)
quarter_store_sum_t <- reshape(quarter_store_sum,idvar="Store",timevar ='Q_Flag',direction="wide")
quarter_store_sum_t_GR <- transform(quarter_store_sum_t,
GR=((Weekly_Sales.Q3_2012-Weekly_Sales.Q2_2012)/Weekly_Sales.Q2_2012))
View(quarter_store_sum_t_GR)
quarter_store_sum_t_GR <- transform(quarter_store_sum_t,
GR=((Weekly_Sales.Q3_2012-Weekly_Sales.Q2_2012)/Weekly_Sales.Q2_2012))
quarter_store_sum_t_GR <- transform(quarter_store_sum_t,
GR=((Weekly_Sales.Q3_2012-Weekly_Sales.Q3_2012)/Weekly_Sales.Q2_2012))
quarter_store_sum_t_GR <- transform(quarter_store_sum_t,
GR=((Weekly_Sales.Q3_2012-Weekly_Sales.Q2_2012)/Weekly_Sales.Q2_2012))
quarter_store_sum_t <- reshape(quarter_store_sum,idvar="Store",timevar ='Q_Flag',direction="wide")
# summarizing and then reshaping
quarter_store_sum <- aggregate(Weekly_Sales~Store+Q_Flag,quarter_store,sum)
quarter_store_sum_t <- reshape(quarter_store_sum,idvar="Store",timevar ='Q_Flag',direction="wide")
quarter_store_sum_t_GR <- transform(quarter_store_sum_t,
GR=((Weekly_Sales.Q3_2012-Weekly_Sales.Q2_2012)/Weekly_Sales.Q2_2012))
jpeg('store_growth_q3.jpg')
ggplot(quarter_store_sum_t_GR, aes(Store, GR))+geom_bar(stat='identity',
color='dark red',
fill = 'dark red')
dev.off()
rm(list = ls())
getwd()
my_packages <- c("ggplot2","lubridate","dplyr", "plyr","ggplot2",
"lubridate","raster","zoo","sp",
"usdm","lmtest","forecast")
lapply(my_packages, require, character.only = TRUE)
stores <- read.csv('Walmart_Store_sales.csv')
head(stores)
summary(stores)
colnames(stores)
str(stores)
stores$Date <- as.Date(stores$Date, format = c("%m-%d-%Y"))
str(stores)
each_store <- aggregate(Weekly_Sales ~ Store, stores,sum)
each_store <- arrange(each_store, desc(Weekly_Sales))
max(each_store)
options(scipen = 999)
jpeg('max_store_sale.jpg')
ggplot(each_store, aes(Store, Weekly_Sales)) +
geom_bar(stat = 'identity', color = ' dark blue',
fill = ' dark blue')
dev.off()
each_store_sd <- aggregate(Weekly_Sales~Store,stores, sd)
each_store_sd <- rename(each_store_sd, c(Weekly_Sales = 'SD_Sales'))
max(each_store_sd)
each_store_mean <- aggregate(Weekly_Sales~Store, stores, mean)
each_store_mean <- rename(each_store_mean, c(Weekly_Sales = 'Mean_Sales'))
each_store_mean_sd <- cbind(each_store_mean, each_store_sd)
each_store_mean_sd_coeff <- transform(each_store_mean_sd, Coeff = SD_Sales/Mean_Sales)
quarter_store <- transform(stores, Q_Flag= ifelse((Date>='2012-04-01' & Date<= '2012-06-30'),"Q2_2012",
ifelse((Date>='2012-07-01' & Date<= '2012-09-30'),"Q3_2012","-")))
# confirming start and end date for each quarter
aggregate(Date ~ Q_Flag, quarter_store, min)
aggregate(Date ~ Q_Flag, quarter_store, max)
# summarizing and then reshaping
quarter_store_sum <- aggregate(Weekly_Sales~Store+Q_Flag,quarter_store,sum)
str(quarter_store_sum)
quarter_store_sum_t <- reshape(quarter_store_sum,idvar="Store",timevar ='Q_Flag',direction="wide")
quarter_store_sum_t_GR <- transform(quarter_store_sum_t,
GR=((Weekly_Sales.Q3_2012-Weekly_Sales.Q2_2012)/Weekly_Sales.Q2_2012))
View(quarter_store_sum_t_GR)
GR=((Weekly_Sales.Q3_2012-Weekly_Sales.Q2_2012)/Weekly_Sales.Q2_2012))
jpeg('store_growth_q3.jpg')
ggplot(quarter_store_sum_t_GR, aes(Store, GR))+geom_bar(stat='identity',
color='dark red',
fill = 'dark red')
dev.off()
non_holiday_Sales <- filter(stores,Holiday_Flag==0)
Avg_non_holiday_Sales <- mean(non_holiday_Sales$Weekly_Sales)
Declining_Holiday_Sales <- filter(stores,Weekly_Sales>Avg_non_holiday_Sales & Holiday_Flag==1)
unique(Declining_Holiday_Sales$Date)
View(stores)
Declining_Holiday_Sales <- filter(stores,Weekly_Sales>Avg_non_holiday_Sales & Holiday_Flag==1)
unique(Declining_Holiday_Sales$Date)
View(Declining_Holiday_Sales)
fit <- lm(Weekly_Sales ~ Holiday_Flag + Temperature + Fuel_Price
+ CPI + Unemployment, stores)
summary(fit)
#Dropping the insignificant vars ie Temperature and Fuel Price
fit1 <- lm(Weekly_Sales ~ Holiday_Flag + CPI + Unemployment, stores)
summary(fit1)
# concatenating 6 m forecast and actual
Actual_vs_Forecast_last_6_m <- cbind(Forecasted_Sales_6m,Actual_Sales_6m)
library(dplyr)
store_month_year <- transform(stores,Year =as.numeric(format(Date,"%Y"))
,Month =as.numeric(format(Date,"%m")))
store_month_year_filtered <- store_month_year %>% dplyr:: select(Weekly_Sales,Year,Month)
# rolling up sales at month level
Walmart_Rolledup <- aggregate(Weekly_Sales~Year+Month,
store_month_year_filtered,sum)
# sorting in year and month order
Walmart_sorted <- arrange(Walmart_Rolledup,Year,Month)
# creating a Column with month and year of sale
Walmart_TS <- transform(Walmart_sorted,
Time_Of_Sale = as.Date(paste(Year,"-",Month,"-",1,sep=""),
format="%Y-%m-%d"))[,c(4,3)]
# Build up ARIMA model to forecast last 6 months i.e as in input utilize only till
# Predict next 6 months i.e June to Oct 2010. Check for MAPE
# Building ARIMA model
Walmart_ARIMA <- auto.arima(Walmart_TS[1:30,2])
Walmart_ARIMA = arima(Walmart_TS[1:30,2],order=c(2,1,2))
Forecasted_Sale <- forecast(Walmart_ARIMA,h=6)
Forecasted_Sale
View(Forecasted_Sale)
plot(Forecasted_Sale)
# 6 months forecast
Forecasted_Sales <- as.data.frame(Forecasted_Sale)
Forecasted_Sales_6m <- Forecasted_Sales[,1]
# 6 m actual
Actual_Sales_6m <- Walmart_TS[31:36,]
# concatenating 6 m forecast and actual
Actual_vs_Forecast_last_6_m <- cbind(Forecasted_Sales_6m,Actual_Sales_6m)
View(Actual_vs_Forecast_last_6_m)
Actual_vs_Forecast_last_6_m_deviation <- transform(Actual_vs_Forecast_last_6_m,
Errors = abs(Forecasted_Sales_6m-Weekly_Sales)/Weekly_Sales)
ggplot(Actual_vs_Forecast_last_6_m, aes(Time_Of_Sale, Weekly_Sales))+
scale_y_continuous("Actual Sales", sec.axis = Forecasted_Sales_6m,
name = 'Forecast Sales') + geom_bar(stat = 'identity')
+ geom_bar(stat = 'identity')
ggplot(Actual_vs_Forecast_last_6_m, aes(Time_Of_Sale, Weekly_Sales))+
scale_y_continuous(sec.axis = sec_axis())
+ geom_bar(stat = 'identity')
ggplot(Actual_vs_Forecast_last_6_m, aes(x=Time_Of_Sale))+
geom_line(y=Forecasted_Sales_6m)+
geom_line(y=Weekly_Sales)
ggplot(Actual_vs_Forecast_last_6m, aes(x=Time_Of_Sale))+
geom_line(y=Forecasted_Sales_6m)+
geom_line(y=Weekly_Sales)
ggplot(Actual_vs_Forecast_last_6_m, aes(x=Time_Of_Sale))+
geom_line(y=Forecasted_Sales_6m)
ggplot(Actual_vs_Forecast_last_6_m, aes(Time_Of_Sale, Forecasted_Sales_6m))+
geom_line()
ggplot(Actual_vs_Forecast_last_6_m, aes(Time_Of_Sale, Forecasted_Sales_6m))+
geom_line()+ggtitle("Six-Month Sales Forecast")
p1<-ggplot(Actual_vs_Forecast_last_6_m, aes(Time_Of_Sale, Forecasted_Sales_6m))+
geom_line()+ggtitle("Six-Month Sales Forecast")
p2<-ggplot(Actual_vs_Forecast_last_6_m, aes(Time_Of_Sale, Weekly_Sales))+
geom_line()+ggtitle("Actual Sales")
p2
p1
p1+p2
library(patchwork)
install.packages('patchwork')
library(patchwork)
p1+p2
Actual_vs_Forecast_last_6_m_deviation <- transform(Actual_vs_Forecast_last_6_m,
Errors = abs(Forecasted_Sales_6m-Weekly_Sales)/Weekly_Sales)
MAPE <- mean(Actual_vs_Forecst_last_6_m_deviation$Errors)
# concatenating 6 m forecast and actual
Actual_vs_Forecast_last_6_m <- cbind(Forecasted_Sales_6m,Actual_Sales_6m)
Actual_vs_Forecast_last_6_m_deviation <- transform(Actual_vs_Forecast_last_6_m,
Errors = abs(Forecasted_Sales_6m-Weekly_Sales)/Weekly_Sales)
MAPE <- mean(Actual_vs_Forecst_last_6_m_deviation$Errors)
MAPE <- mean(Actual_vs_Forecast_last_6_m_deviation$Errors)
MAPE <- mean(Actual_vs_Forecast_last_6_m_deviation$Errors)
MAPE
knitr::stitch('Walmart_Sales.r')
install.packages("patchwork")
install.packages("patchwork")
install.packages("patchwork")
install.packages("patchwork")
install.packages("patchwork")
install.packages("patchwork")
install.packages("patchwork")
install.packages('knitr')
install.packages("knitr")
install.packages('rmarkdown')
rm(list = ls())
q()
